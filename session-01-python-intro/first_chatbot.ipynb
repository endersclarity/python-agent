{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04aa7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.6.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.11.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.41.4-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading openai-2.6.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m895.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.11.1-cp313-cp313-macosx_11_0_arm64.whl (314 kB)\n",
      "Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp313-cp313-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m885.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, sniffio, python-dotenv, jiter, idna, h11, distro, certifi, annotated-types, typing-inspection, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [openai]16/17\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.11.0 certifi-2025.10.5 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.11.1 openai-2.6.1 pydantic-2.12.3 pydantic-core-2.41.4 python-dotenv-1.1.1 sniffio-1.3.1 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "998d4cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fb797f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-pr...izYAA\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True, dotenv_path=\"../.env\")\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print (my_api_key[:5] + \"...\" + my_api_key[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ae0019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openai\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_api_key)\n",
    "\n",
    "def ask_question(prompt):\n",
    "    print(f\"User asked: {prompt}\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Answer as concisely as possible.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    print (response)\n",
    "    return response.choices[0].message.content  \n",
    "    # response.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90daaf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User asked: What's the largest star?\n",
      "ChatCompletion(id='chatcmpl-CUa6zz191F5B9PWXil2O0DD9HgUom', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='UY Scuti. It’s a red supergiant and is the largest known star by radius, with an estimated radius around 1,700 solar radii (estimates often quoted roughly 1,500–2,000 R_sun). That corresponds to a diameter of about 15–16 AU. Distance is about 9,500 light-years away. Measurements can vary, and other extremely large stars are contenders, but UY Scuti is the usual answer for “largest star” by size.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761404689, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1520, prompt_tokens=29, total_tokens=1549, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=1408, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "\n",
      "OpenAI says: UY Scuti. It’s a red supergiant and is the largest known star by radius, with an estimated radius around 1,700 solar radii (estimates often quoted roughly 1,500–2,000 R_sun). That corresponds to a diameter of about 15–16 AU. Distance is about 9,500 light-years away. Measurements can vary, and other extremely large stars are contenders, but UY Scuti is the usual answer for “largest star” by size.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = input(\"Ask something: \")\n",
    "\n",
    "response = ask_question(user_prompt)\n",
    "print(\"\\nOpenAI says:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d6cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User asked: how far is Sun from moon?\n",
      "ChatCompletion(id='chatcmpl-CUa7awxlWF7Oeps4Kx8LCHOQxLtEk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='About 150 million kilometers (1 astronomical unit). The Moon is ~384,400 km from Earth, so Sun–Moon distance varies roughly from 149.2 million km (new moon) to 150.0 million km (full moon).', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1761404726, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=1146, prompt_tokens=31, total_tokens=1177, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=1088, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "\n",
      "OpenAI says: About 150 million kilometers (1 astronomical unit). The Moon is ~384,400 km from Earth, so Sun–Moon distance varies roughly from 149.2 million km (new moon) to 150.0 million km (full moon).\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while True:\n",
    "    # Ask user for a question\n",
    "    user_prompt = input(\"Ask something: \")\n",
    "\n",
    "    if (user_prompt.lower() != 'quit'):\n",
    "        # Get and print the response\n",
    "        response = ask_question(user_prompt)\n",
    "        print(\"\\nOpenAI says:\", response)\n",
    "        \n",
    "        # add delay of 3 seconds\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        print(\"Exiting the loop. Goodbye!\")\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89438bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
